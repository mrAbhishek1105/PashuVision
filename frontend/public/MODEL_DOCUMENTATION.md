# PashuVision AI Model Technical Report

## 1. Model Architecture: MobileNetV2

PashuVision utilizes **MobileNetV2**, a convolutional neural network architecture optimized for mobile and edge devices. It is chosen for its balance between high accuracy and low computational cost (low latency).

### Key Architectural Features:
*   **Depthwise Separable Convolutions**: Unlike standard convolutions that perform spatial and channel-wise processing together, MobileNetV2 splits this into two lighter steps:
    1.  *Depthwise Convolution*: Filters input channels.
    2.  *Pointwise Convolution*: Combines the filtered channels.
    *Benefit*: Reduces the number of parameters and calculation cost by ~8-9x.
*   **Inverted Residuals**: Connects bottlenecks (layers with fewer channels) to preserve information flow, preventing data loss during compression.
*   **Linear Bottlenecks**: Uses linear activation (instead of ReLU) in the bottleneck layers to prevent destroying information in low-dimensional space.

### Custom Classification Head
The original MobileNetV2 is designed for 1000 general classes (ImageNet). We replaced the top layer with a custom "Head" for our 5 specific breeds:

1.  **Global Average Pooling**: Flattens 2D feature maps into a 1D vector.
2.  **Dense Layer (128 units, ReLU)**: Learns complex non-linear combinations of features.
3.  **Dropout (0.5)**: Randomly turns off 50% of neurons during training to prevent memorization (overfitting).
4.  **Output Layer (5 units, Softmax)**: Outputs a probability distribution summing to 1.0 (100%) for our 5 breeds.

---

## 2. Image Preprocessing

Before the AI sees an image, it must be mathematically transformed:

1.  **Resize**: All images are squashed to `224 x 224` pixels (MobileNetV2 standard input).
2.  **Pixel Normalization ([-1, 1])**:
    *   Standard pixels: `0 to 255`.
    *   Formula: `(Pixel / 127.5) - 1`.
    *   Result: Pixels range from `-1.0` (black) to `1.0` (white).
    *   *Why?*: Neural networks converge faster and are more stable with zero-centered data.

### Data Augmentation (Training Only)
To teach the model invariance (recognizing a cow even if it's tilted or zoomed), we apply random transformations during training:
*   **Rotation**: Â±20 degrees.
*   **Shear/Zoom**: Up to 20%.
*   **Horizontal Flip**: Mirroring the image.

---

## 3. Training Strategy: Transfer Learning

We did not train the model from scratch (which requires millions of images). We used **Transfer Learning**:

### Phase 1: Feature Extraction
*   **Base Model**: Comparison logic (weights) loaded from ImageNet (trained on 14 million images).
*   **Action**: We "froze" the base model so it wouldn't forget generic shapes (edges, curves, textures). we only trained our custom 5-breed classifier head.
*   **Result**: The model quickly learned to map generic visual features to our specific breeds.

### Phase 2: Fine-Tuning
*   **Action**: We "unfroze" the top 50 layers of the base model.
*   **Learning Rate**: Set to extremely low (`1e-5`).
*   **Goal**: To slightly adjust the high-level filters to specifically understand *cattle fur textures* and *horn shapes* instead of generic objects like cars or cats.

---

## 4. How to Update & Retrain

The system is designed to be "Living". As you collect more photos, you can make the model smarter.

### Step 1: Add Data
1.  Navigate to `ml_engine/dataset/`.
2.  Open the folder of the breed you want to improve (e.g., `dataset/Gir`).
3.  Paste new images (JPG/PNG).
    *   *Tip*: Ensure images are clean and clearly show the animal.
    *   *Tip*: You can add a completely NEW folder (e.g., `dataset/Kankrej`) to add a new breed.

### Step 2: Run Training
1.  Open Terminal.
2.  Go to the ML directory:
    ```bash
    cd ml_engine
    ```
3.  Run the training script:
    ```bash
    python train_model.py
    ```
4.  Wait for the process to finish. It will automatically:
    *   Train the model.
    *   Save `model.h5` to `backend/models/`.
    *   Save a new `class_map.json` (handling any new breeds you added).

### Step 3: Restart Backend
1.  Stop the current Flask backend (Ctrl+C).
2.  Start it again:
    ```bash
    cd backend
    python app.py
    ```
3.  The new model is now live!

---
*Generated by PashuVision AI Team*
